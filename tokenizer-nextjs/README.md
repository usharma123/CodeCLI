# Token Counter - Next.js Application

A modern, interactive Next.js application that calculates and visualizes the number of tokens in text using OpenAI's tiktoken library.

![Token Counter](https://img.shields.io/badge/Next.js-14-black?style=flat-square&logo=next.js)
![TypeScript](https://img.shields.io/badge/TypeScript-5.3-blue?style=flat-square&logo=typescript)
![Tailwind CSS](https://img.shields.io/badge/Tailwind-3.3-38bdf8?style=flat-square&logo=tailwind-css)

## âœ¨ Features

- ğŸ”¢ **Real-time Token Counting** - Automatically calculates tokens as you type
- ğŸ¨ **Visual Tokenization** - Color-coded token display with hover tooltips
- ğŸ“Š **Detailed Statistics** - Character count, word count, tokens, and chars-per-token ratio
- ğŸ¯ **Multiple Encoding Models** - Support for cl100k_base, p50k_base, and r50k_base
- ğŸ” **Token Breakdown** - View detailed token IDs and decoded values
- âœ… **Verification** - Ensures concatenated tokens match original input
- ğŸŒ“ **Dark Mode** - Automatic dark mode support
- ğŸ“± **Responsive Design** - Works seamlessly on desktop and mobile

## ğŸš€ Getting Started

### Prerequisites

- Node.js 18.x or higher
- npm, yarn, pnpm, or bun

### Installation

1. **Clone or navigate to the project directory:**
   ```bash
   cd tokenizer-nextjs
   ```

2. **Install dependencies:**
   ```bash
   npm install
   # or
   yarn install
   # or
   pnpm install
   # or
   bun install
   ```

3. **Run the development server:**
   ```bash
   npm run dev
   # or
   yarn dev
   # or
   pnpm dev
   # or
   bun dev
   ```

4. **Open your browser:**
   Navigate to [http://localhost:3000](http://localhost:3000)

## ğŸ“¦ Building for Production

```bash
npm run build
npm start
```

This will create an optimized production build and start the server.

## ğŸ—ï¸ Project Structure

```
tokenizer-nextjs/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ tokenize/
â”‚   â”‚   â”‚       â””â”€â”€ route.ts          # API endpoint for tokenization
â”‚   â”‚   â”œâ”€â”€ globals.css               # Global styles
â”‚   â”‚   â”œâ”€â”€ layout.tsx                # Root layout
â”‚   â”‚   â””â”€â”€ page.tsx                  # Main page component
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Sidebar.tsx               # Information sidebar
â”‚   â”‚   â”œâ”€â”€ StatsDisplay.tsx          # Statistics cards
â”‚   â”‚   â”œâ”€â”€ TokenDetails.tsx          # Expandable token details
â”‚   â”‚   â””â”€â”€ TokenVisualizer.tsx       # Visual token display
â”‚   â””â”€â”€ lib/
â”‚       â””â”€â”€ types.ts                  # TypeScript type definitions
â”œâ”€â”€ public/                           # Static assets
â”œâ”€â”€ next.config.js                    # Next.js configuration
â”œâ”€â”€ tailwind.config.ts                # Tailwind CSS configuration
â”œâ”€â”€ tsconfig.json                     # TypeScript configuration
â””â”€â”€ package.json                      # Project dependencies
```

## ğŸ¯ Usage

1. **Select an encoding model** from the dropdown (default: cl100k_base for GPT-4/GPT-3.5-turbo)
2. **Enter or paste your text** in the text area
3. **View results automatically** including:
   - Total token count
   - Character, word, and token statistics
   - Visual tokenization with color-coded tokens
   - Detailed token breakdown with IDs

## ğŸ”§ Encoding Models

- **cl100k_base**: Used by GPT-4, GPT-3.5-turbo, and text-embedding-ada-002
- **p50k_base**: Used by Codex models and text-davinci-002/003
- **r50k_base**: Used by GPT-3 models (davinci, curie, babbage, ada)

## ğŸ’¡ Why Token Count Matters

- **API Costs**: OpenAI and other LLM providers charge based on token usage
- **Token Limits**: Models have maximum token limits for input and output
- **Prompt Optimization**: Understanding tokenization helps create more efficient prompts
- **Cost Management**: Knowing token counts helps estimate and control API costs

## ğŸ› ï¸ Technologies Used

- **[Next.js 14](https://nextjs.org/)** - React framework with App Router
- **[TypeScript](https://www.typescriptlang.org/)** - Type-safe JavaScript
- **[Tailwind CSS](https://tailwindcss.com/)** - Utility-first CSS framework
- **[tiktoken](https://github.com/openai/tiktoken)** - OpenAI's tokenization library
- **[React](https://react.dev/)** - UI library

## ğŸ“ API Reference

### POST `/api/tokenize`

Tokenizes the provided text using the specified encoding.

**Request Body:**
```json
{
  "text": "Your text here",
  "encoding": "cl100k_base"
}
```

**Response:**
```json
{
  "success": true,
  "stats": {
    "tokenCount": 10,
    "characterCount": 50,
    "wordCount": 8,
    "charsPerToken": 5.0
  },
  "tokens": [
    {
      "id": 9906,
      "position": 1,
      "text": "Your"
    }
  ],
  "tokenIds": [9906, 1495, 1618]
}
```

## ğŸ¤ Contributing

Contributions are welcome! Feel free to submit issues or pull requests.

## ğŸ“„ License

This project is open source and available under the MIT License.

## ğŸ™ Acknowledgments

- Built with [Next.js](https://nextjs.org/)
- Tokenization powered by [tiktoken](https://github.com/openai/tiktoken)
- Styled with [Tailwind CSS](https://tailwindcss.com/)

## ğŸ“§ Support

If you have any questions or run into issues, please open an issue on GitHub.

---

**Migrated from Streamlit to Next.js** - Enjoy a faster, more interactive experience! ğŸš€
